{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etiquetamento Morfológico com NLTK\n",
    "Como as palavras variam de classe gramatical dependendo do contexto em que estão inseridas, vamos trabalhar com dados (etiquetados) em nível de sentença ao invés de palavras. Começaremos por carregar os dados que usaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ('de', 'PREP'), ('Cr$', 'CUR'), ('1,4', 'NUM'), ('milhão', 'N'), ('em', 'PREP|+'), ('a', 'ART'), ('venda', 'N'), ('de', 'PREP|+'), ('a', 'ART'), ('Pinhal', 'NPROP'), ('em', 'PREP'), ('São', 'NPROP'), ('Paulo', 'NPROP')], [('Programe', 'V'), ('sua', 'PROADJ'), ('viagem', 'N'), ('a', 'PREP|+'), ('a', 'ART'), ('Exposição', 'NPROP'), ('Nacional', 'NPROP'), ('do', 'NPROP'), ('Zebu', 'NPROP'), (',', ','), ('que', 'PRO-KS-REL'), ('começa', 'V'), ('dia', 'N'), ('25', 'N|AP')], ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package mac_morpho to\n",
      "[nltk_data]     C:\\Users\\Leonardo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package mac_morpho is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importa a biblioteca\n",
    "import nltk.corpus\n",
    "nltk.download('mac_morpho')\n",
    "from nltk.corpus import mac_morpho\n",
    "#Carrega as sentença rotuladas do Corpus\n",
    "sentencas_etiquetadas = mac_morpho.tagged_sents()\n",
    "print (sentencas_etiquetadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etiquetagem mais simples é associar a mesma tag para cada token. Isso pode parecer um passo insignificante mas estabelece uma baseline importante para o desempenho do tagger. A fim de conseguir o melhor resultado, etiquetamos cada palavra com a tag mais provável/frequente usando o comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [tag for (word, tag) in mac_morpho.tagged_words()]\n",
    "nltk.FreqDist(tags).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'V', 'N', 'PREP', 'CUR', 'NUM', 'N', 'PREP|+', 'ART', 'N', 'PREP|+', 'ART', 'NPROP', 'PREP', 'NPROP', 'NPROP', 'V', 'PROADJ', 'N', 'PREP|+', 'ART', 'NPROP', 'NPROP', 'NPROP', 'NPROP', ',', 'PRO-KS-REL', 'V', 'N', 'N|AP', 'N', 'ADJ', 'KC', 'N', 'PREP', 'N', 'V', 'N', 'PREP', 'N', 'ADJ', 'ART', 'N', 'PREP|+', 'ART', 'N', 'PREP|+', 'ART', 'ADJ', 'N', 'PREP|+', 'ART', 'N', 'V', 'PREP|+', 'ART', 'ART', 'N', 'V', 'ADJ', 'ART', 'N', 'PREP', 'NUM', 'NUM', 'N', 'PREP|+', 'ART', 'N', 'PREP|+', 'ART', 'N', 'N|AP', ',', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', ',', 'ART', 'ADJ', 'N', 'PREP', 'V', 'VAUX', 'V', 'ART', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'ART', 'N', 'ADJ', 'PREP', 'N', 'PREP', 'N', 'V', ',', 'PREP', 'N', 'ADJ', ',', 'NUM', 'N', ',', 'N', 'NUM', 'N', 'ADJ', 'PREP|+', 'ART', 'N', 'PREP', 'N', 'PREP', 'N', ',', 'PREP', 'N', 'PREP|+', 'ART', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', '(', 'NPROP', ')', 'ART', 'NPROP', 'V', 'PREP', 'PROADJ', 'N', 'ADJ', 'KS', 'ART', 'N', 'ADJ', 'V', 'ADJ', 'PREP', 'ART', 'ADJ', 'N', 'PREP', 'N', 'ADJ', '\"', 'ART', 'N', 'PREP|+', 'ART', 'N', 'ADJ', 'V', 'PREP', 'ADJ', 'N', 'PREP', 'N', 'PREP', 'N', '\"', 'ART', 'N', 'PREP|+', 'ART', 'N', 'ADJ', ',', 'NPROP', 'NPROP', ',', 'V', 'ART', 'N', 'PREP|+', 'ART', 'N', ',', 'PCP', 'PREP|+', 'ART', 'N', 'PREP', 'N', 'PREP|+', 'ART', 'N', 'ADJ', 'ART', 'ADJ', 'N', 'PREP', 'N', 'PREP|+', 'ART', 'N', '(', 'NUM', 'N', ')', 'V', 'ART', 'N', 'PREP|+', 'ART', 'N', 'ADJ', ',', 'V', 'ART', 'N', 'N', 'PREP', 'ART', 'NPROP', 'NPROP', 'NPROP', ',', 'PREP', 'NPROP', 'NPROP', ',', 'V', 'ADV', 'ART', 'N', 'PREP', 'N', 'ADJ', 'ART', 'N', ',', 'PREP', 'ART', 'N', 'PREP', 'N', ',', 'VAUX', 'PCP', 'PREP|+', 'ART', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'ART', 'N', 'NPROP', 'NPROP', ',', 'PREP|+', 'ART', 'NPROP', ',', 'KC', 'ART', 'N', 'PREP|+', 'ART', 'N', 'NPROP', 'NPROP', 'NPROP', 'V', 'ART', 'N', 'PREP|+', 'ART', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'PREP', 'V', 'PREP|+', 'ART', 'N', 'PREP|+', 'ART', 'N', ',', 'NPROP', 'NPROP', ',', 'ART', 'ADJ', 'N', 'PREP', 'N', 'ADJ', ',', 'ADJ', 'PREP', 'V', 'N', 'KC', 'ART', 'N', 'PREP|+', 'ART', 'N', 'NPROP', 'NPROP', 'NPROP', 'V', 'ART', 'ADJ', 'N', 'PREP|+', 'ART', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'PROPESS', 'V', 'NPROP', 'NPROP', 'NPROP', 'NPROP', ',', 'PRO-KS-REL', 'PROPESS', 'V', 'PREP', 'NUM', 'N', 'PREP', 'N', 'N', 'ADJ', 'ART', 'N', 'PRO-KS-REL', 'VAUX', 'V', 'ART', 'N', 'ADJ', 'PREP', 'N', 'VAUX', 'V', 'ART', 'N', 'PREP|+', 'ART', 'N', 'PREP|+', 'ART', 'N', 'ART', 'N', 'V', 'PREP|+', 'ART', 'N', 'NPROP', 'NPROP', ',', 'PREP', 'NPROP', 'NPROP', ',', 'PRO-KS-REL', 'V', 'PREP|+', 'ART', 'N', 'PCP', 'PREP|+', 'ART', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'PREP', 'NPROP', 'NPROP', 'PREP|+', 'ART', 'N', 'PREP|+', 'ART', 'ADJ', 'NUM', 'N', ',', 'ART', 'N', 'ADJ', 'ADJ', 'ADJ', 'VAUX', 'V', 'PREP', 'ADJ', 'N', 'PREP|+', 'ART', 'N', 'PREP', 'PROADJ', 'ADJ', 'N', 'PRO-KS-REL', 'V', 'PREP', 'N', ',', 'V|+', 'PROPESS', 'ART', 'N', 'PREP|+', 'ART', 'N', 'ADJ', 'PREP|+', 'PROADJ', 'N', 'KC', 'PDEN', 'ART', 'N', 'PREP|+', 'ART', 'N', 'ADJ', 'PREP', 'PREP', 'PREP', 'ART', 'N', 'N', 'PREP|+', 'PROSUB', 'V', 'ART', 'ADJ', 'N', 'PREP|+', 'ART', 'NPROP', '(', 'N', 'N|AP', ')', ',', 'PRO-KS-REL', 'V', 'ART', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', 'NPROP', '-', 'NPROP', 'PROADJ', 'N', 'ADJ', 'V', 'PREP|+', 'ART', 'N', 'NPROP', ',', 'PREP', 'ART', 'N', 'N|AP', ',', 'PRO-KS-REL', 'V']\n"
     ]
    }
   ],
   "source": [
    "print(tags[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos criar um tagger que etiqueta qualquer coisa com N, considerando que a classe de substantivo é a mais frequente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Estou', 'N'),\n",
       " ('bem', 'N'),\n",
       " (',', 'N'),\n",
       " ('mas', 'N'),\n",
       " ('não', 'N'),\n",
       " ('tenho', 'N'),\n",
       " ('certeza', 'N'),\n",
       " ('se', 'N'),\n",
       " ('viajarei', 'N'),\n",
       " ('amanhã', 'N'),\n",
       " ('às', 'N'),\n",
       " ('8:30', 'N'),\n",
       " ('.', 'N')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"Estou bem, mas não tenho certeza\n",
    "... se viajarei amanhã às 8:30.\"\"\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "etiqPadrao = nltk.tag.DefaultTagger('N')\n",
    "etiqPadrao.tag(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " O tagger padrão atribui sua tag a cada palavra, até mesmo palavras que nunca foram encontradas antes. Como na língua portuguesa a maioria das novas palavras são substantivos, o tagger padrão pode ajudar a melhor a robustez do sistema de processamento da linguagem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Tagging\n",
    "O unigram tagger é baseado em um simples algoritmo estatístico no qual para cada token é atribuído uma tag que seja a mais provável para aquele token em particular. Por exemplo, ele vai atribuir a tag N a qualquer ocorrência da palavra Piauí, desde que Piauí seja mais usada como um substantivo do que ser usado como um verbo. Um unigram tagger comporta-se apenas como um tagger de pesquisa, exceto que há uma técnica mais conveniente para configurá-lo, chamada treinamento. No exemplo de código a seguir, nós treinamos um unigram tagger, usando-o para etiquetar uma sentença.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = nltk.corpus.mac_morpho.tagged_sents()\n",
    "texto = 'manhã está ensolarada'\n",
    "tokens = nltk.word_tokenize(texto)\n",
    "unigram_tagger = nltk.tag.UnigramTagger(tagged_sents)\n",
    "unigram_tagger.tag(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por convenção do NLTK, um token etiquetado é representado por uma tupla consistindo do token e da etiqueta. Aqui nos vemos que A é ART, um artigo; manhã é N, um substantivo; está é V, um verbo (estar); e ensolarada é ADJ, um adjetivo.\n",
    "Quando realizamos uma tarefa de processamento de linguagem baseada em unigramas, estamos usando apenas um item do contexto. Nos casos de etiquetagem, consideramos apenas o token corrente, isolado de qualquer contexto maior. Dado esse modelo, o melhor que podemos fazer é marcar cada palavra com a sua tag a priori mais provável. Isso significa que podemos etiquetar um token erroneamente, por exemplo, ao atribuir a palavra cedo como advérbio independentemente se ela aparece em um contexto como verbo.\n",
    "Um n-gram tagger é uma generalização de um unigram tagger cujo contexto é a palavra corrente em conjunto com os n-1 tokens precedentes, portanto o n-gram tagger seleciona a tag que é mais provável no contexto dado. A classe n-gram tagger usa um Córpus de treinamento etiquetado para determinar qual tag da parte do discurso é mais provável para cada contexto. \n",
    "Aqui vemos casos especiais de n-gram tagger, ou seja, bigram tagger e trigram tagger. Primeiramente os treinamos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tagged_sents = nltk.corpus.mac_morpho.tagged_sents()\n",
    "t0 = nltk.DefaultTagger('N')\n",
    "t1 = nltk.UnigramTagger(tagged_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(tagged_sents, backoff=t1)\n",
    "t3 = nltk.TrigramTagger(tagged_sents, backoff=t2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que estamos combinando vários taggers para aumentar a cobertura e precisão do modelo usando o algoritmo backoff. Note também que especificamos o backoff tagger quando o etiquetador é inicializado de modo que o treinamento pode tirar proveito dele. Assim, se o bigram tagger atribuir a mesma tag tal como unigram tagger em um determinado contexto, o bigram tagger descarta a instância de treinamento, isso mantém o modelo bigram tagger o menor possível, a mesma relação também ocorre entre o trigram tagger e o bigram tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando um tagger\n",
    "O treinamento de um etiquetador em um Corpus grande pode tomar um tempo significativo, então é mais conveniente salvar um modelo treinado em um arquivo para mais tarde usa-lo. Vamos salvar nosso tagger para o arquivo mac_morpho.pkl.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "output = open('mac_morpho.pkl', 'wb')\n",
    "dump(t3, output, -1)\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando um tagger treinado\n",
    "Agora nos podemos carregar um modelo treinado usando:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "input = open('mac_morpho.pkl', 'rb')\n",
    "tagger = load(input)\n",
    "input.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manhã', 'N'), ('está', 'V'), ('ensolarada', 'ADJ')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

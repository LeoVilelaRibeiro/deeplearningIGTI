{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula de NLTK - Professor Leonardo Vilela \n",
    "Para testar se o NLTK está instalado, execute o seguinte código no prompt do Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso haja um report de não instalação, você deverá instalar o pacote conforme o professor explicará.\n",
    "Na ausência de qualquer módulo do NLTK, você pode fazer o download de todos os módulos do NLTK executando o seguinte código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando um Corpus e a Classe Text\n",
    "Até aqui trabalhamos com textos utilizando strings e listas de strings. A partir de agora nossos textos serão extraídos a partir de Córpus. O NLTK inclui alguns Córpus que possuem utilidades diversas na análise e no processamento de textos. Um exemplo é o Córpus machado, que inclui uma série de textos do autor Machado de Assis. A sequência de código a seguir demonstra como importar esse Córpus para os nossos programas e em seguida lista os ids de todos os textos presentes no Córpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package machado to\n",
      "[nltk_data]     C:\\Users\\Leonardo\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contos/macn001.txt', 'contos/macn002.txt', 'contos/macn003.txt', 'contos/macn004.txt', 'contos/macn005.txt', 'contos/macn006.txt', 'contos/macn007.txt', 'contos/macn008.txt', 'contos/macn009.txt', 'contos/macn010.txt', 'contos/macn011.txt', 'contos/macn012.txt', 'contos/macn013.txt', 'contos/macn014.txt', 'contos/macn015.txt', 'contos/macn016.txt', 'contos/macn017.txt', 'contos/macn018.txt', 'contos/macn019.txt', 'contos/macn020.txt', 'contos/macn021.txt', 'contos/macn022.txt', 'contos/macn023.txt', 'contos/macn024.txt', 'contos/macn025.txt', 'contos/macn026.txt', 'contos/macn027.txt', 'contos/macn028.txt', 'contos/macn029.txt', 'contos/macn030.txt', 'contos/macn031.txt', 'contos/macn032.txt', 'contos/macn033.txt', 'contos/macn034.txt', 'contos/macn035.txt', 'contos/macn036.txt', 'contos/macn037.txt', 'contos/macn038.txt', 'contos/macn039.txt', 'contos/macn040.txt', 'contos/macn041.txt', 'contos/macn042.txt', 'contos/macn043.txt', 'contos/macn044.txt', 'contos/macn045.txt', 'contos/macn046.txt', 'contos/macn047.txt', 'contos/macn048.txt', 'contos/macn049.txt', 'contos/macn050.txt', 'contos/macn051.txt', 'contos/macn052.txt', 'contos/macn053.txt', 'contos/macn054.txt', 'contos/macn055.txt', 'contos/macn056.txt', 'contos/macn057.txt', 'contos/macn058.txt', 'contos/macn059.txt', 'contos/macn060.txt', 'contos/macn061.txt', 'contos/macn062.txt', 'contos/macn063.txt', 'contos/macn064.txt', 'contos/macn065.txt', 'contos/macn066.txt', 'contos/macn067.txt', 'contos/macn068.txt', 'contos/macn069.txt', 'contos/macn070.txt', 'contos/macn071.txt', 'contos/macn072.txt', 'contos/macn073.txt', 'contos/macn074.txt', 'contos/macn075.txt', 'contos/macn076.txt', 'contos/macn077.txt', 'contos/macn078.txt', 'contos/macn079.txt', 'contos/macn080.txt', 'contos/macn081.txt', 'contos/macn082.txt', 'contos/macn083.txt', 'contos/macn084.txt', 'contos/macn085.txt', 'contos/macn086.txt', 'contos/macn087.txt', 'contos/macn088.txt', 'contos/macn089.txt', 'contos/macn090.txt', 'contos/macn091.txt', 'contos/macn092.txt', 'contos/macn093.txt', 'contos/macn094.txt', 'contos/macn095.txt', 'contos/macn096.txt', 'contos/macn097.txt', 'contos/macn098.txt', 'contos/macn099.txt', 'contos/macn100.txt', 'contos/macn101.txt', 'contos/macn102.txt', 'contos/macn103.txt', 'contos/macn104.txt', 'contos/macn105.txt', 'contos/macn106.txt', 'contos/macn107.txt', 'contos/macn108.txt', 'contos/macn109.txt', 'contos/macn110.txt', 'contos/macn111.txt', 'contos/macn112.txt', 'contos/macn113.txt', 'contos/macn114.txt', 'contos/macn115.txt', 'contos/macn116.txt', 'contos/macn117.txt', 'contos/macn118.txt', 'contos/macn119.txt', 'contos/macn120.txt', 'contos/macn121.txt', 'contos/macn122.txt', 'contos/macn123.txt', 'contos/macn124.txt', 'contos/macn125.txt', 'contos/macn126.txt', 'contos/macn127.txt', 'contos/macn128.txt', 'contos/macn129.txt', 'contos/macn130.txt', 'contos/macn131.txt', 'contos/macn132.txt', 'contos/macn133.txt', 'contos/macn134.txt', 'contos/macn135.txt', 'contos/macn136.txt', 'contos/macn137.txt', 'critica/mact01.txt', 'critica/mact02.txt', 'critica/mact03.txt', 'critica/mact04.txt', 'critica/mact05.txt', 'critica/mact06.txt', 'critica/mact07.txt', 'critica/mact08.txt', 'critica/mact09.txt', 'critica/mact10.txt', 'critica/mact11.txt', 'critica/mact12.txt', 'critica/mact13.txt', 'critica/mact14.txt', 'critica/mact15.txt', 'critica/mact16.txt', 'critica/mact17.txt', 'critica/mact18.txt', 'critica/mact19.txt', 'critica/mact20.txt', 'critica/mact21.txt', 'critica/mact22.txt', 'critica/mact23.txt', 'critica/mact24.txt', 'critica/mact25.txt', 'critica/mact26.txt', 'critica/mact27.txt', 'critica/mact28.txt', 'critica/mact29.txt', 'critica/mact30.txt', 'critica/mact31.txt', 'critica/mact32.txt', 'critica/mact33.txt', 'critica/mact34.txt', 'critica/mact35.txt', 'critica/mact36.txt', 'critica/mact37.txt', 'critica/mact38.txt', 'critica/mact39.txt', 'critica/mact40.txt', 'critica/mact41.txt', 'critica/mact42.txt', 'critica/mact43.txt', 'critica/mact44.txt', 'critica/mact45.txt', 'cronica/macr01.txt', 'cronica/macr02.txt', 'cronica/macr03.txt', 'cronica/macr04.txt', 'cronica/macr05.txt', 'cronica/macr06.txt', 'cronica/macr07.txt', 'cronica/macr08.txt', 'cronica/macr09.txt', 'cronica/macr10.txt', 'cronica/macr11.txt', 'cronica/macr12.txt', 'cronica/macr13.txt', 'cronica/macr14.txt', 'cronica/macr15.txt', 'cronica/macr16.txt', 'cronica/macr17.txt', 'cronica/macr18.txt', 'cronica/macr19.txt', 'cronica/macr20.txt', 'cronica/macr21.txt', 'cronica/macr22.txt', 'cronica/macr23.txt', 'cronica/macr24.txt', 'miscelanea/mams01.txt', 'miscelanea/mams02.txt', 'miscelanea/mams03.txt', 'miscelanea/mams04.txt', 'miscelanea/mams05.txt', 'miscelanea/mams06.txt', 'miscelanea/mams07.txt', 'miscelanea/mams08.txt', 'miscelanea/mams09.txt', 'miscelanea/mams10.txt', 'poesia/maps01.txt', 'poesia/maps02.txt', 'poesia/maps03.txt', 'poesia/maps04.txt', 'poesia/maps05.txt', 'poesia/maps06.txt', 'poesia/maps07.txt', 'romance/marm01.txt', 'romance/marm02.txt', 'romance/marm03.txt', 'romance/marm04.txt', 'romance/marm05.txt', 'romance/marm06.txt', 'romance/marm07.txt', 'romance/marm08.txt', 'romance/marm09.txt', 'romance/marm10.txt', 'teatro/matt01.txt', 'teatro/matt02.txt', 'teatro/matt03.txt', 'teatro/matt04.txt', 'teatro/matt05.txt', 'teatro/matt06.txt', 'teatro/matt07.txt', 'teatro/matt08.txt', 'teatro/matt09.txt', 'teatro/matt10.txt', 'traducao/matr01.txt', 'traducao/matr02.txt', 'traducao/matr03.txt']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('machado')\n",
    "from nltk.corpus import machado\n",
    "print(machado.fileids())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada arquivo corresponde a um dos trabalhos de Machado de Assis. A lista completa pode ser conferida no arquivo README do Córpus: machado.readme(). Para este minicurso trabalharemos com a obra Memórias Póstumas de Brás Cubas.\n",
    "Assim como em strings do Python, podemos obter um texto de um Córpus como uma sequência de caracteres utilizando o método .raw(id). O trecho de código a seguir retorna a obra Memórias Póstumas de Brás Cubas e exibe um trecho desse texto em uma faixa que vai do 5600º caractere ao 5800º caractere em utilizando o fatiamento em faixa de strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essa anônima, ainda que não parenta, padeceu mais do que as parentas.\n",
      "É verdade, padeceu mais. Não digo que se carpisse, não digo que se deixasse\n",
      "rolar pelo chão, convulsa. Nem o meu óbito era coisa a\n"
     ]
    }
   ],
   "source": [
    "raw_text = machado.raw('romance/marm05.txt')\n",
    "print(raw_text[5600:5800]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como já vimos, enxergar um texto como uma sequência de caracteres não é a forma mais eficiente. Por esse motivo, o NLTK também permite retornar um texto como uma lista de tokens utilizando o método .words(id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Romance', ',', 'Memórias', 'Póstumas', 'de', 'Brás', ...]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77098"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto1 = machado.words('romance/marm05.txt')\n",
    "print(texto1)\n",
    "len(texto1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma outra possibilidade é utilizar a classe Text do NLTK, que além de representar o texto como uma sequência de tokens, também implementa uma série de métodos muito úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Romance , Memórias Póstumas de Brás Cubas ,...>\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "bras = Text(machado.words('romance/marm05.txt'))\n",
    "print(bras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a classe Text podemos, por exemplo, encontrar uma palavra dentro de diferentes contextos usando o método .concordance(string):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 138 matches:\n",
      "De pé , à cabeceira da cama , com os olhos estúpidos , a boca entreaberta , a t\n",
      "orelhas . Pela minha parte fechei os olhos e deixei - me ir à ventura . Já agor\n",
      "xões de cérebro enfermo . Como ia de olhos fechados , não via o caminho ; lembr\n",
      "gelos eternos . Com efeito , abri os olhos e vi que o meu animal galopava numa \n",
      "me apareceu então , fitando - me uns olhos rutilantes como o sol . Tudo nessa f\n",
      " mim mesmo . Então , encarei - a com olhos súplices , e pedi mais alguns anos .\n",
      "o alto de uma montanha . Inclinei os olhos a uma das vertentes , e contemplei ,\n",
      "ilhão , e , não obstante , porque os olhos do delírio são outros , eu via tudo \n",
      "cifração da eternidade . E fixei os olhos , e continuei a ver as idades , que \n",
      " esperto , concordava meu pai ; e os olhos babavam - se - lhe de orgulho , e el\n",
      "te , e , repetido o mote , cravar os olhos na testa de uma senhora , depois tos\n",
      "avrear de estômagos satisfeitos ; os olhos moles e úmidos , ou vivos e cálidos \n",
      "m estacado de orquestra , e todos os olhos se voltavam para o glosador . Quem f\n",
      " . Eu via isso , porque arrastava os olhos da compota para ele e dele para a co\n",
      " eu segui - os . O Vilaça levava nos olhos umas chispas de vinho e de volúpia .\n",
      "es ... D . Eusébia levou o lenço aos olhos . O glosador vasculhava na memória a\n",
      " estupefação imobilizou a todos ; os olhos espraiavam - se a uma e outra banda \n",
      "a aula , dava um pulo , circulava os olhos chamejantes , dizia - nos os últimos\n",
      ", deixava - se estar quieto , com os olhos espetados no ar . Uma flor , o Quinc\n",
      "u forcejava por trazer a bigode . Os olhos , vivos e resolutos , eram a minha f\n",
      " pensativa , ou levantou para mim os olhos cobiçosos . De todas porém a que me \n",
      "pouco ou nada comi , porque só tinha olhos para a dona da casa . Que gentil que\n",
      "erramava - se - lhe a felicidade dos olhos , e eu sentia - me feliz com vê - la\n",
      " meu amor ! Eu agradeci - lho com os olhos úmidos . No dia seguinte levei - lhe\n",
      "proposta . Marcela ouviu - me com os olhos no ar , sem responder logo ; como in\n"
     ]
    }
   ],
   "source": [
    "bras.concordance('olhos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também encontrar palavras com distribuição de texto similar utilizando o método .similar(string):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "já leitor lhe dizer com menos contar deixei cheguei desferirem peito\n",
      "corpo fazer porém ver casamento soltar quebrei titubear sacrifício\n"
     ]
    }
   ],
   "source": [
    "bras.similar('chegar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos encontrar palavras em um contexto com ajuda de expressões regulares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estúpidos; e; fechados; e; rutilantes; súplices; a; do; ,; babavam;\n",
      "na; moles; se; da; umas; .; espraiavam; chamejantes; espetados; ,;\n",
      "cobiçosos; para; ,; úmidos; no; ;; de; de; fitos; a; naquele; do; ,;\n",
      "pretos; as; estúpidos; ao; às; ...; ,; fúlgidos; de; ,; .; de; pretos;\n",
      "tão; de; para; a; chisparam; para; me; da; ,; ,; uma; no; na; para;\n",
      "se; em; .; em; .; de; ,; no; nela; tinham; ;; cintilantes; o; dos; e;\n",
      ",; de; de; dela; vermelhos; .; e; .; o; ,; constantemente; para; ,; ,;\n",
      "para; ,; ao; ,; na; na; baixos; no; mais; no; se; dela; do; no; ,;\n",
      "lampejantes; rasos; todos; ,; e; do; pelos; de; ao; .; lhe; de;\n",
      "enfermos; :; ,; .; e; da; fixos; .; fitos; ,; ,; bonitos; de; ...; .;\n",
      "de; algum; a; ;; fitos; em\n"
     ]
    }
   ],
   "source": [
    "bras.findall(\"<olhos> (<.*>)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de Córpus de textos como o machado, o NLTK também possui Córpus anotados como o MacMorpho [Fonseca et al., 2015], que podem ser utilizados em tarefas de part-of-speech tagging, um tópico que será discutido posteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords \n",
    "StopWords são palavras que podem ser consideradas irrelevantes para o entedimento do sentido de um texto, ou seja, palavras semanticamente irrelavantes. Exemplos: as, e, os, de, para, com, sem, foi. Essas palavras são geralmente removidas de um texto durante a fase de pré-processamento. O NLTK possui uma lista de stopwords para o Português:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Leonardo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colocações e Bigramas\n",
    "\n",
    "Em linguística, uma colocação é uma sequência de palavras ou termos que co-ocorrem mais frequentemente do que seria esperado por acaso. Por exemplo, “vinho tinto” é uma colocação enquanto “o vinho” não é. Uma característica de colocações é que elas são resistentes à substituição com palavras que têm sentidos semelhantes; por exemplo, vinho marrom soa definitivamente estranho. As colocações são expressões parcial ou totalmente fixas que se estabelecem através do uso repetido dependente do contexto.\n",
    "Entender e extrair colocações de textos pode ser útil na análise semântica e pragmática. Essa tarefa pode ser facilitada pelo NLTK com o uso de n-grams, onde n representa o tamanho da sequência da colocação. Por exemplo, uma sequência de duas palavras é chamada de bigrama. O NLTK implementa uma função bigrams() que extrai de uma lista de tokens uma lista de pares de palavras:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('meu', 'coração'),\n",
       " ('coração', 'está'),\n",
       " ('está', 'bem'),\n",
       " ('bem', 'machucado')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "list(bigrams(['meu', 'coração', 'está', 'bem', 'machucado']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode perceber, colocações são essencialmente bigramas frequentes, exceto que precisamos prestar mais atenção aos casos que envolvem palavras raras. Em geral, precisamos encontrar bigramas que ocorram mais frequentemente do que seria esperado baseado na frequência de palavras individuais. A função collocations() faz exatamente isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quincas Borba; Lobo Neves; alguma coisa; Brás Cubas; meu pai; que não;\n",
      "dia seguinte; não sei; Com efeito; que era; Meu pai; alguns instantes;\n",
      "outra vez; outra coisa; por exemplo; que ele; mim mesmo; coisa\n",
      "nenhuma; mesma coisa; não era\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import machado\n",
    "from nltk.text import Text\n",
    "bras = Text(machado.words('romance/marm05.txt'))\n",
    "bras.collocations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemmers (Radicais)\n",
    "O NLTK também possui o stemmer RSLP em Português. O código a seguir demonstra seu funcionamento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Leonardo\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copi\n",
      "pais\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping stemmers\\rslp.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('rslp')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "print(stemmer.stem(\"copiar\"))\n",
    "print(stemmer.stem(\"paisagem\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenização\n",
    "Vimos anteriormente como tokenizar um texto utilizando expressões regulares. O NLTK também possui módulos para tokenização. Podemos tokenizar uma sequência de caracteres utilizando o método .word_tokenize(string):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Leonardo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', ',', 'o', 'professor', 'Léo', 'agradece', 'a', 'atenção', 'de', 'todos', 'os', 'alunos']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "sentence = \"Olá, o professor Léo agradece a atenção de todos os alunos\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui eu termino esta aula agradecendo a todos a vocês pela atenção e também aos autores Jardeson Leandro Nascimento Barbosa, João Paulo Albuquerque Vieira,Roney Lira de Sales Santos, Gilvan Veras Magalhães Junior, Mariana dos Santos Muniz, Raimundo Santos Moura que escreveram um artigo super legal (III Escola Regional de Informática do Piauí. Livro Anais - Artigos e Minicursos, v. 1, n. 1, p. 336-360, jun, 2017.) que serviu de base para essa demonstração."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
